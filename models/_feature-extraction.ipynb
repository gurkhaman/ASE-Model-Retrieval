{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###([Mastering the Huggingface CLIP Model: How to Extract Embeddings and Calculate Similarity for Text and Images](https://codeandlife.com/2023/01/26/mastering-the-huggingface-clip-model-how-to-extract-embeddings-and-calculate-similarity-for-text-and-images/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import torch\n",
    "from transformers import AutoTokenizer, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_DATASET_DIR = \"/workspaces/ASE-Model-Retrieval/data/imagenet/.cache/hf_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset_dict = load_from_disk(HF_DATASET_DIR)\n",
    "hf_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_features(labels):\n",
    "    text_inputs = tokenizer(\n",
    "        [f\"a photo of a {label}\" for label in labels], padding=True, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**text_inputs)\n",
    "    return text_features\n",
    "\n",
    "def get_image_features(images):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: subclass_EntleBucher-German_shepherd-bluetick-croquet_ball-tench\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Border_terrier-Lakeland_terrier-Lhasa-Norfolk_terrier-Sussex_spaniel\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Border_collie-Pomeranian-cairn-kelpie-terrapin\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-Scottie-baseball-giant_schnauzer-minibus\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Norwich_terrier-banana-bloodhound-kite-minivan\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Norwich_terrier-Scottie-dingo-minivan-red_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bouvier-Hungarian_pointer-jackfruit-leopard-miniature_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_custard_apple-flat_coated_retriever-minibus-red_wolf-sports_car\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Italian_greyhound-Labrador_retriever-Welsh_springer_spaniel-bloodhound-snow_leopard\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_beaker-brown_bear-groenendael-keeshond-stingray\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_terrier-Shetland_sheepdog-dingo-miniature_pinscher-softcoated_wheaten_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_beagle-chow-dipper-great_white-stingray\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_water_spaniel-Lhasa-lion-minibus-tow_truck\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_French_bulldog-affenpinscher-bloodhound-husky-sloth_bear\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-English_springer-banana-tandem_bicycle-tow_truck\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Blenheim_spaniel-Brabancon_griffon-Samoyed-Sealyham_terrier-lion\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_French_bulldog-Newfoundland-Samoyed-Weimaraner-hen\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Saluki-Siberian_husky-baseball-pineapple-whippet\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_German_short_haired_pointer-Weimaraner-beer_bottle-sloth_bear-wine_bottle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Italian_greyhound-Sealyham_terrier-Walker_foxhound-Yorkshire_terrier-minivan\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Scottish_deerhound-West_Highland_white_terrier-bell_pepper-borzoi-great_white\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Dandie_Dinmont_terrier-EntleBucher-Irish_water_spaniel-grey_wolf-husky\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_bluetick-brambling-kuvasz-sign_traffic_light-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_beagle-great_white-softcoated_wheaten_terrier-standard_poodle-wine_bottle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Blenheim_spaniel-Siberian_husky-basketball-finch-strawberry\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Chihuahua-bloodhound-brown_bear-tennis_ball-terrapin\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Airedale-Great_Dane-Saint_Bernard-giant_schnauzer-otter_hound\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Cardigan-English_foxhound-English_springer-silky_terrier-water_jug\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bernese_mountain_dog-Blenheim_spaniel-custard_apple-minivan-pug\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Rottweiler-affenpinscher-box-chickadee-whippet\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Walker_foxhound-brown_bear-husky-leopard-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Border_collie-Sussex_spaniel-ambulance-lynx-terrapin\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-Norwich_terrier-Siberian_husky-tennis_ball-toy_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Great_Dane-basset_hound-lion-standard_schnauzer-stingray\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_wolfhound-curly_coated_retriever-fire_engine-goldfinch-police_wagon\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Leonberg-Persian-basset_hound-minivan-strawberry\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Ibizan_hound-briard-grey_wolf-softcoated_wheaten_terrier-tiger_shark\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_wolfhound-Pembroke-bald_eagle-pomegranate-volleyball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Afghan_hound-cheetah-kite-schipperke-standard_schnauzer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_German_shepherd-Greater_Swiss_Mountain_dog-Siamese-ambulance-limousine\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Rhodesian_ridgeback-standard_schnauzer-tabby-tiger_shark-water_bottle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Saint_Bernard-Samoyed-cairn-chow-otter_hound\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Chesapeake_Bay_retriever-Welsh_springer_spaniel-coffee_mug-scooter-snow_leopard\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Afghan_hound-Siamese-minivan-tiger_cat-tractor_trailer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Hungarian_pointer-box-chickadee-jay-leatherback\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Saint_Bernard-ambulance-malamute-stingray-tennis_ball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Border_terrier-Irish_setter-cocker_spaniel-coyote-standard_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_basset_hound-kelpie-malamute-tench-water_jug\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Border_collie-Boston_terrier-English_setter-miniature_poodle-red_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-Persian-basset_hound-junco-lynx\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Australian_terrier-German_short_haired_pointer-Irish_terrier-goldfinch-white_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Afghan_hound-Ibizan_hound-goldfish-keeshond-toy_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brittany_spaniel-bloodhound-brambling-grey_owl-papillon\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-Lhasa-Staffordshire_bullterrier-jay-rugby_ball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_setter-French_bulldog-Ibizan_hound-beaker-cocker_spaniel\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Ibizan_hound-Leonberg-kelpie-loggerhead-scooter\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Chesapeake_Bay_retriever-EntleBucher-Granny_Smith-Irish_setter-bull_mastiff\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Kerry_blue_terrier-garbage_truck-goldfish-rooster-taxi\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Lhasa-basset_hound-box-boxer-malinois\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Lhasa-Old_English_sheepdog-Saluki-Staffordshire_bullterrier-white_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_water_spaniel-Pekinese-Shetland_sheepdog-custard_apple-rv\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Leonberg-affenpinscher-ambulance-curly_coated_retriever-police_wagon\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_terrier-Sealyham_terrier-bell_pepper-borzoi-clumber_spaniel\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Leonberg-Saint_Bernard-Shetland_sheepdog-standard_schnauzer-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_French_bulldog-Great_Pyrenees-dingo-leatherback-lynx\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Siberian_husky-cheetah-chow-grey_wolf-sports_car\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Italian_greyhound-Kerry_blue_terrier-Norwich_terrier-box-giant_schnauzer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Afghan_hound-Staffordshire_bullterrier-coyote-mud-sign_street_sign\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_wolfhound-affenpinscher-bell_pepper-boxer-croquet_ball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Hungarian_pointer-coonhound-lion-strawberry-tandem_bicycle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brittany_spaniel-Chesapeake_Bay_retriever-Irish_setter-Saluki-Siberian_husky\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_banana-cocker_spaniel-coyote-flat_coated_retriever-mountain_bike\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Scottish_deerhound-bloodhound-boxer-grey_owl-robin\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Sealyham_terrier-bloodhound-dipper-tench-white_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-beagle-clumber_spaniel-standard_schnauzer-wine_bottle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bouvier-baseball-goldfish-miniature_pinscher-tow_truck\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Labrador_retriever-Persian-chow-police_wagon-tench\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brabancon_griffon-Doberman-Leonberg-cougar-finch\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Appenzeller-Chesapeake_Bay_retriever-Gordon_setter-Old_English_sheepdog-Persian\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Persian-bloodhound-pickup_truck-redbone-tractor_trailer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Labrador_retriever-Scottish_deerhound-bluetick-clumber_spaniel-great_white\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Greater_Swiss_Mountain_dog-Labrador_retriever-Pekinese-banana-terrapin\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_finch-hen-redbone-tabby-water_jug\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Granny_Smith-Pekinese-brambling-curly_coated_retriever-tiger_cat\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Norwegian_elkhound-Shetland_sheepdog-kelpie-lemon-tiger_cat\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_setter-Yorkshire_terrier-jaguar-kuvasz-mountain_bike\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Afghan_hound-Irish_terrier-Italian_greyhound-collie-finch\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Japanese_spaniel-Maltese-Yorkshire_terrier-lemon-pug\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Old_English_sheepdog-Rhodesian_ridgeback-bull_mastiff-pug-volleyball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Siamese-Staffordshire_bullterrier-husky-kite-sign_street_sign\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bedlington_terrier-German_shepherd-affenpinscher-bull_mastiff-white_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_German_short_haired_pointer-Labrador_retriever-Mexican_hairless-Sealyham_terrier-magpie\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Tibetan_mastiff-cougar-police_wagon-snow_leopard-tench\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bedlington_terrier-box-chow-giant_schnauzer-lemon\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Labrador_retriever-Shih_Tzu-black_bear-brown_bear-jay\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_setter-Japanese_spaniel-box-chow-mountain_bike\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Afghan_hound-English_setter-Ibizan_hound-junco-orange\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Doberman-Scottish_deerhound-beer_bottle-rugby_ball-strawberry\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brittany_spaniel-Irish_water_spaniel-Walker_foxhound-loggerhead-mud\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_water_spaniel-great_white-malinois-orange-toy_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bernese_mountain_dog-Labrador_retriever-papillon-toy_poodle-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Appenzeller-box-clumber_spaniel-polar_bear-trolleybus\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Norwich_terrier-Shih_Tzu-ambulance-dipper-jay\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Blenheim_spaniel-Pembroke-borzoi-boxer-great_white\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Blenheim_spaniel-Weimaraner-West_Highland_white_terrier-beagle-tiger_shark\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Greater_Swiss_Mountain_dog-Welsh_springer_spaniel-flat_coated_retriever-lion-mountain_bike\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brabancon_griffon-Egyptian-Granny_Smith-Irish_setter-chickadee\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-English_springer-croquet_ball-finch-mud\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bedlington_terrier-Rhodesian_ridgeback-flat_coated_retriever-garbage_truck-tandem_bicycle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Sussex_spaniel-bell_pepper-giant_schnauzer-kite-polar_bear\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-borzoi-loggerhead-tiger_cat-whippet\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Maltese-ambulance-chickadee-chow-pomegranate\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Old_English_sheepdog-Pembroke-Saluki-chow-kite\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bedlington_terrier-Greater_Swiss_Mountain_dog-Norfolk_terrier-borzoi-indigo\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_bluetick-dingo-fig-taxi-terrapin\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_German_short_haired_pointer-golden_retriever-kite-malinois-sign_traffic_light\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Appenzeller-Egyptian-English_foxhound-German_shepherd-Leonberg\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-Norwich_terrier-Pomeranian-silky_terrier-tiger_shark\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-Hungarian_pointer-banana-pickup_truck-wirehaired_fox_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Pembroke-beer_bottle-malinois-mud-stingray\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-Pekinese-Persian-grey_wolf-indigo\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brittany_spaniel-Lhasa-affenpinscher-baseball-great_white\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-Pekinese-kelpie-lemon-standard_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-grey_owl-loggerhead-miniature_pinscher-tiger\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Mexican_hairless-bell_pepper-otter_hound-silky_terrier-tennis_ball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Rhodesian_ridgeback-Weimaraner-bluetick-fig-grey_owl\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Granny_Smith-bell_pepper-clumber_spaniel-finch-whippet\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-beaker-indigo-miniature_pinscher-miniature_schnauzer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Granny_Smith-goldfinch-grey_wolf-tandem_bicycle-tiger\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Italian_greyhound-Labrador_retriever-Yorkshire_terrier-stingray-tiger_cat\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Lhasa-clumber_spaniel-fig-rugby_ball-water_jug\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Leonberg-garbage_truck-minivan-sports_car-toy_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-Hungarian_pointer-affenpinscher-kite-polar_bear\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-Bouvier-Japanese_spaniel-Tibetan_mastiff-Walker_foxhound\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-Pomeranian-beaker-fig-grey_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Great_Dane-Irish_water_spaniel-Saint_Bernard-beagle-pineapple\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Appenzeller-English_setter-Ibizan_hound-beer_glass-redbone\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_briard-lemon-standard_schnauzer-stingray-tiger\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_setter-Italian_greyhound-malamute-miniature_poodle-snow_leopard\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Welsh_springer_spaniel-grey_owl-papillon-toy_poodle-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_goldfinch-limousine-miniature_poodle-papillon-sloth_bear\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_black_bear-goldfinch-hen-keeshond-toy_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Kerry_blue_terrier-Saluki-brown_bear-tandem_bicycle-tiger_shark\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Kerry_blue_terrier-Pekinese-briard-groenendael-snow_leopard\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-Norfolk_terrier-miniature_pinscher-schipperke-wirehaired_fox_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Afghan_hound-West_Highland_white_terrier-coyote-goldfinch-grey_owl\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Great_Pyrenees-borzoi-garbage_truck-miniature_pinscher-tow_truck\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Appenzeller-Ibizan_hound-Scottish_deerhound-West_Highland_white_terrier-baseball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Old_English_sheepdog-Yorkshire_terrier-pickup_truck-redbone-sign_traffic_light\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-Border_terrier-bluetick-bulbul-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_cheetah-dalmatian-junco-lemon-silky_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Siamese-Welsh_springer_spaniel-banana-beagle-giant_schnauzer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_German_shepherd-Newfoundland-croquet_ball-standard_poodle-tow_truck\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-ambulance-fig-komondor-leopard\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Shih_Tzu-Tibetan_mastiff-cocker_spaniel-red_wolf-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brittany_spaniel-French_bulldog-Welsh_springer_spaniel-beagle-mud\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_cairn-leopard-otter_hound-tiger-toy_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Persian-basketball-box-tow_truck-tractor_trailer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_wolfhound-Siberian_husky-pineapple-pomegranate-schipperke\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_bell_pepper-red_wolf-redbone-tench-toy_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Chihuahua-Staffordshire_bullterrier-great_white-orange-softcoated_wheaten_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Sussex_spaniel-bluetick-golden_retriever-indigo-mud\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-Rhodesian_ridgeback-goldfish-pickup_truck-police_wagon\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Japanese_spaniel-Scottie-fire_engine-golden_retriever-hen\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_beer_bottle-briard-komondor-polar_bear-tabby\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Welsh_springer_spaniel-beaker-clumber_spaniel-coffee_mug-sports_car\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_fig-miniature_pinscher-mud-tench-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Mexican_hairless-collie-cougar-robin-whippet\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Hungarian_pointer-Persian-baseball-clumber_spaniel-otter_hound\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_cocker_spaniel-coonhound-croquet_ball-sports_car-white_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Saint_Bernard-Siberian_husky-ambulance-coyote-tennis_ball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_beagle-custard_apple-dipper-papillon-water_bottle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Weimaraner-bald_eagle-basset_hound-cairn-tow_truck\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Tibetan_mastiff-goldfish-mountain_bike-tabby-tractor_trailer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_German_shepherd-Persian-komondor-kuvasz-rooster\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Norfolk_terrier-custard_apple-flat_coated_retriever-leopard-volleyball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Newfoundland-Samoyed-giant_schnauzer-indigo-lynx\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Doberman-Irish_water_spaniel-Mexican_hairless-beer_bottle-taxi\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Blenheim_spaniel-Chihuahua-English_springer-Lakeland_terrier-sign_street_sign\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Weimaraner-papillon-rv-sign_traffic_light-toy_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Norwegian_elkhound-Rhodesian_ridgeback-fire_engine-indigo-toy_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_bald_eagle-croquet_ball-great_white-junco-tabby\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Lhasa-Samoyed-bull_mastiff-leatherback-limousine\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Border_terrier-baseball-basenji-malinois-soccer_ball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Greater_Swiss_Mountain_dog-jay-miniature_poodle-rugby_ball-scooter\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_terrier-Siamese-dipper-flat_coated_retriever-red_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_bald_eagle-jay-scooter-terrapin-tiger_cat\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Doberman-Irish_terrier-coyote-indigo-miniature_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Ibizan_hound-Labrador_retriever-clumber_spaniel-minibus-stingray\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Boston_terrier-Leonberg-Old_English_sheepdog-cheetah-tiger_cat\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_beer_bottle-giant_schnauzer-golden_retriever-tiger-white_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_wolfhound-Pembroke-bloodhound-limousine-taxi\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Border_collie-basset_hound-fig-lion-robin\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-Pembroke-Siamese-beer_glass-pomegranate\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Blenheim_spaniel-Labrador_retriever-leopard-sports_car-stingray\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Shih_Tzu-ambulance-great_white-jaguar-tiger\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Hungarian_pointer-cocker_spaniel-dalmatian-jackfruit-schipperke\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brabancon_griffon-Norfolk_terrier-Samoyed-grey_wolf-jay\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Greater_Swiss_Mountain_dog-Irish_terrier-Lhasa-cocker_spaniel-curly_coated_retriever\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Newfoundland-Norwich_terrier-brown_bear-giant_schnauzer-red_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bernese_mountain_dog-English_setter-Granny_Smith-Persian-Scottish_deerhound\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-leatherback-malamute-rooster-scooter\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Greater_Swiss_Mountain_dog-custard_apple-hen-husky-rooster\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_wolfhound-Tibetan_mastiff-croquet_ball-goldfish-limousine\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_wolfhound-Norfolk_terrier-baseball-fire_engine-tandem_bicycle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Doberman-Pomeranian-Tibetan_terrier-dalmatian-volleyball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Great_Dane-Sussex_spaniel-dipper-rugby_ball-whippet\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bouvier-Samoyed-garbage_truck-giant_schnauzer-papillon\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_grey_wolf-miniature_poodle-police_wagon-sign_traffic_light-standard_schnauzer\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bernese_mountain_dog-bell_pepper-cheetah-lemon-miniature_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-Kerry_blue_terrier-West_Highland_white_terrier-otter_hound-stingray\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bouvier-Irish_wolfhound-basset_hound-chow-groenendael\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Border_terrier-Italian_greyhound-beagle-bulbul-redbone\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Dandie_Dinmont_terrier-Lakeland_terrier-beagle-goldfinch-whippet\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bernese_mountain_dog-bulbul-dalmatian-dingo-pomegranate\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_West_Highland_white_terrier-chickadee-hen-standard_poodle-toy_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Appenzeller-German_shepherd-Labrador_retriever-loggerhead-wirehaired_fox_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_setter-Newfoundland-fig-terrapin-trolleybus\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-Old_English_sheepdog-Pekinese-beer_glass-miniature_pinscher\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Greater_Swiss_Mountain_dog-Samoyed-goldfinch-groenendael-polar_bear\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Gordon_setter-Mexican_hairless-husky-malinois-tabby\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Blenheim_spaniel-Gordon_setter-Italian_greyhound-Siberian_husky-golden_retriever\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Sussex_spaniel-junco-minibus-standard_poodle-tiger_cat\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_foxhound-coffee_mug-dipper-kite-vulture\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Dandie_Dinmont_terrier-Egyptian-bell_pepper-coonhound-taxi\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Ibizan_hound-Norwegian_elkhound-Rhodesian_ridgeback-Sussex_spaniel-black_bear\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Shetland_sheepdog-basenji-coffee_mug-leatherback-lion\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Gordon_setter-lion-miniature_pinscher-tiger-water_bottle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-Irish_wolfhound-Norwegian_elkhound-mountain_bike-tandem_bicycle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Tibetan_mastiff-grey_owl-minibus-rv-sloth_bear\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_setter-Greater_Swiss_Mountain_dog-briard-indigo-komondor\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Afghan_hound-Egyptian-Lhasa-groenendael-mud\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Irish_water_spaniel-Pomeranian-basset_hound-beer_bottle-tiger_cat\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Appenzeller-Irish_setter-chickadee-junco-tow_truck\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brabancon_griffon-English_springer-cairn-strawberry-tiger_cat\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_cheetah-custard_apple-fig-pomegranate-red_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Brabancon_griffon-English_foxhound-Old_English_sheepdog-goldfish-malinois\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Scottie-golden_retriever-leatherback-miniature_pinscher-mud\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_French_bulldog-Pekinese-brambling-redbone-softcoated_wheaten_terrier\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Airedale-Boston_terrier-otter_hound-rooster-rv\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_French_bulldog-basset_hound-indigo-robin-rooster\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_American_Staffordshire_terrier-English_foxhound-basset_hound-lemon-red_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Saluki-Sealyham_terrier-basketball-giant_schnauzer-kuvasz\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_EntleBucher-Saluki-grey_wolf-sign_street_sign-white_wolf\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Bernese_mountain_dog-Dandie_Dinmont_terrier-EntleBucher-malamute-polar_bear\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Mexican_hairless-chow-magpie-tench-water_bottle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Blenheim_spaniel-Hungarian_pointer-borzoi-brown_bear-groenendael\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Saint_Bernard-Staffordshire_bullterrier-dingo-miniature_schnauzer-volleyball\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_Old_English_sheepdog-Yorkshire_terrier-goldfinch-rugby_ball-toy_poodle\n",
      "torch.Size([5, 768])\n",
      "Processing dataset: subclass_English_setter-Irish_terrier-Rottweiler-chickadee-dalmatian\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text_features\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, dataset \u001b[38;5;129;01min\u001b[39;00m hf_dataset_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[0;34m(dataset_name, dataset)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m unique_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m----> 5\u001b[0m text_features \u001b[38;5;241m=\u001b[39m \u001b[43mget_text_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_features\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m, in \u001b[0;36mget_text_features\u001b[0;34m(labels)\u001b[0m\n\u001b[1;32m      2\u001b[0m text_inputs \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma photo of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     text_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_features\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:1259\u001b[0m, in \u001b[0;36mCLIPModel.get_text_features\u001b[0;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1254\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1255\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1256\u001b[0m )\n\u001b[1;32m   1257\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1259\u001b[0m text_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1268\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m text_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1269\u001b[0m text_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_projection(pooled_output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:960\u001b[0m, in \u001b[0;36mCLIPTextTransformer.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask(attention_mask, hidden_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 960\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    970\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm(last_hidden_state)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:883\u001b[0m, in \u001b[0;36mCLIPEncoder.forward\u001b[0;34m(self, inputs_embeds, attention_mask, causal_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    875\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    876\u001b[0m         encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    877\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    880\u001b[0m         output_attentions,\n\u001b[1;32m    881\u001b[0m     )\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 883\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:614\u001b[0m, in \u001b[0;36mCLIPEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    611\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm1(hidden_states)\n\u001b[0;32m--> 614\u001b[0m hidden_states, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    622\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/clip/modeling_clip.py:546\u001b[0m, in \u001b[0;36mCLIPSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    543\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# CLIP text model uses both `causal_attention_mask` and `attention_mask` sequentially.\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    556\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, embed_dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_dataset(dataset_name, dataset):\n",
    "    print(f\"Processing dataset: {dataset_name}\")\n",
    "\n",
    "    unique_labels = list(set(dataset[\"label\"]))\n",
    "    text_features = get_text_features(unique_labels)\n",
    "    print(text_features.shape)\n",
    "\n",
    "for dataset_name, dataset in hf_dataset_dict.items():\n",
    "    process_dataset(dataset_name, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
